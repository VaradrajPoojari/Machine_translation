{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW1_j_rLzjo1"
   },
   "source": [
    "OpenNMT gives us a way to use beam search, which could be tricky to implement efficiently on your own.\n",
    "\n",
    "Configure different models for OpenNMT including Transformer and included sentence piece model.\n",
    "\n",
    "OpenNMT, is similar to other ML frameworks in that it relies on a combination of editable .yaml files and command line tools to run the training procedure.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R24Vt0AksrhX",
    "outputId": "eff6f512-ab19-49ba-dc44-fc2a28f53883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.6.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (708.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 708.0 MB 10 kB/s \n",
      "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 46.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.21.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cu101) (7.1.2)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0+cu101 which is incompatible.\n",
      "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0+cu101 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloning OpenNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2NZIg4rnuUW",
    "outputId": "056a486a-1231-4f47-804a-cf349f33049b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'OpenNMT-py'...\n",
      "remote: Enumerating objects: 17675, done.\u001b[K\n",
      "remote: Counting objects: 100% (631/631), done.\u001b[K\n",
      "remote: Compressing objects: 100% (350/350), done.\u001b[K\n",
      "remote: Total 17675 (delta 373), reused 463 (delta 271), pack-reused 17044\u001b[K\n",
      "Receiving objects: 100% (17675/17675), 273.81 MiB | 24.26 MiB/s, done.\n",
      "Resolving deltas: 100% (12673/12673), done.\n",
      "Obtaining file:///content/OpenNMT-py\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.2.0) (1.6.0+cu101)\n",
      "Collecting torchtext==0.5.0\n",
      "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
      "\u001b[K     |████████████████████████████████| 73 kB 1.3 MB/s \n",
      "\u001b[?25hCollecting configargparse\n",
      "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.2.0) (2.8.0)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.2.0) (1.1.4)\n",
      "Collecting waitress\n",
      "  Downloading waitress-2.1.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
      "\u001b[?25hCollecting pyonmttok<2,>=1.23\n",
      "  Downloading pyonmttok-1.31.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.6 MB 76 kB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.2.0) (3.13)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (1.15.0)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 37.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (4.63.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (1.21.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (2.23.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (3.3.6)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (3.17.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (57.4.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (1.44.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (1.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==2.2.0) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==2.2.0) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py==2.2.0) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py==2.2.0) (4.11.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py==2.2.0) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py==2.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py==2.2.0) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3->OpenNMT-py==2.2.0) (3.2.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->OpenNMT-py==2.2.0) (0.16.0)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==2.2.0) (7.1.2)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==2.2.0) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==2.2.0) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py==2.2.0) (2.0.1)\n",
      "Installing collected packages: sentencepiece, waitress, torchtext, pyonmttok, configargparse, OpenNMT-py\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.11.0\n",
      "    Uninstalling torchtext-0.11.0:\n",
      "      Successfully uninstalled torchtext-0.11.0\n",
      "  Running setup.py develop for OpenNMT-py\n",
      "Successfully installed OpenNMT-py-2.2.0 configargparse-1.5.3 pyonmttok-1.31.0 sentencepiece-0.1.96 torchtext-0.5.0 waitress-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/OpenNMT/OpenNMT-py.git\n",
    "!cd OpenNMT-py; pip install -e .\n",
    "# !wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
    "# !tar xf toy-ende.tar.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UylIL0MBg-NO"
   },
   "source": [
    "\n",
    "### Build the vocab for the Multi30k En-Fr dataset\n",
    "\n",
    "This relies on having a config file with the below information laid out.\n",
    "\n",
    "While just having a vocabulary is fine for some cases, using a sub-word tokenization might help capture morphological information better.\n",
    "\n",
    "To do this, we add ```transforms: [sentencepiece, filtertoolong]``` to both the training and validation corpora in the config file yml.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-VFCCughPuo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1cHXMYBFVhHq",
    "outputId": "11cab5af-3794-4a60-f3f2-4b6e437432a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuIDOdaWlJiK"
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# spacy_en = spacy.load('en_core_web_sm')\n",
    "# # punctuation = set(string.punctuation)\n",
    "# # stop_words = set(stopwords.words('english'))\n",
    "# def tokenize_en(text):\n",
    "#     \"\"\"\n",
    "#     Tokenizes English text from a string into a list of strings (tokens)\n",
    "#     \"\"\"\n",
    "#     token_list =[]\n",
    "#     for tok in spacy_en.tokenizer(text):\n",
    "#       token_list.append(tok.text)\n",
    "\n",
    "#     return ' '.join(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PU0O71Y4hEGw"
   },
   "outputs": [],
   "source": [
    "# import sentencepiece as spm\n",
    "# spm.SentencePieceTrainer.train(input='/content/drive/MyDrive/Lab3/data/train_eng_tok.txt', model_prefix='en',vocab_size=6797)\n",
    "# spm.SentencePieceTrainer.train(input='/content/drive/MyDrive/Lab3/data/train_fre_tok.txt', model_prefix='fr', vocab_size=6797)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93KD6CBVjcQu"
   },
   "outputs": [],
   "source": [
    "## TO DO COMPLETE DATA SAVING\n",
    "\n",
    "# Corpus opts:\n",
    "\n",
    "## TODO COMPLETE CORPUS OPTIONS\n",
    "src_subword_model: ./fr.model\n",
    "tgt_subword_model: ./en.model\n",
    "src_subword_vocab: ./fr.vocab\n",
    "tgt_subword_vocab: ./en.vocab\n",
    "## Where the samples will be written\n",
    "save_data: drive/MyDrive/Lab3/data/run/example\n",
    "## Where the vocab(s) will be written\n",
    "# Prevent overwriting existing files in the folder\n",
    "overwrite: False\n",
    "\n",
    "# Corpus opts:\n",
    "data:\n",
    "    corpus_1:\n",
    "        path_src: ./drive/MyDrive/Lab3/data/train_eng.txt\n",
    "        path_tgt: ./drive/MyDrive/Lab3/data/train_fre.txt\n",
    "        transforms: [sentencepiece, filtertoolong]\n",
    "    valid:\n",
    "        path_src: ./drive/MyDrive/Lab3/data/val_eng.txt\n",
    "        path_tgt: ./drive/MyDrive/Lab3/data/val_fre.txt\n",
    "        transforms: [sentencepiece]\n",
    "\n",
    "\n",
    "\n",
    "# Vocabulary files that were just created\n",
    "src_vocab: drive/MyDrive/Lab3/data/run/example.vocab.src\n",
    "tgt_vocab: drive/MyDrive/Lab3/data/run/example.vocab.tgt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQPweQMQ6S_0",
    "outputId": "cc241f44-9b0c-4a1a-b009-13d51b211f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2022-03-11 05:59:43,906 INFO] Counter vocab from 10000 samples.\n",
      "[2022-03-11 05:59:43,906 INFO] Build vocab on 10000 transformed examples/corpus.\n",
      "[2022-03-11 05:59:43,917 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2022-03-11 05:59:44,224 INFO] Counters src:9483\n",
      "[2022-03-11 05:59:44,224 INFO] Counters tgt:8615\n"
     ]
    }
   ],
   "source": [
    "!onmt_build_vocab -config multi30k.yml -n_sample 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B05G-PaWl0L-"
   },
   "source": [
    "\n",
    "# Train Model\n",
    "\n",
    "Next we will beging training with OpenNMT, again using the same config file, however, below we'll look at the relevant parts.\n",
    "We fill in the multi30k.yaml config to setup a seq2seq model that has a 3 layer RNN encoder 2 layer RNN decoder, MLP attention, with 20% dropout, using Adam as our optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWcx3Uuamdil"
   },
   "outputs": [],
   "source": [
    "## Should have 3 layers in encoder and 2 layers in decoder\n",
    "## 20% dropout and 500 hidden units\n",
    "# Model (note these are actually default values, but I've explicitely written them out to show how you can edit them)\n",
    "decoder_type: rnn\n",
    "encoder_type: rnn \n",
    "enc_layers: 3\n",
    "dec_layers: 2\n",
    "enc_rnn_size: 500\n",
    "dec_rnn_size: 500\n",
    "dropout: 0.2\n",
    "global_attention : mlp\n",
    "# Optimizer settings\n",
    "optim: adam\n",
    "learning_rate: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lo2rlSWWJ2uV",
    "outputId": "c820c4c2-bab6-4f44-a662-d13a13836004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-11 05:59:57,841 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
      "[2022-03-11 05:59:57,842 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2022-03-11 05:59:57,842 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2022-03-11 05:59:57,845 INFO] Parsed 2 corpora from -data.\n",
      "[2022-03-11 05:59:57,846 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
      "[2022-03-11 05:59:57,846 INFO] Loading vocab from text file...\n",
      "[2022-03-11 05:59:57,846 INFO] Loading src vocabulary from drive/MyDrive/Lab3/data/run/example.vocab.src\n",
      "[2022-03-11 05:59:57,872 INFO] Loaded src vocab has 9483 tokens.\n",
      "[2022-03-11 05:59:57,877 INFO] Loading tgt vocabulary from drive/MyDrive/Lab3/data/run/example.vocab.tgt\n",
      "[2022-03-11 05:59:57,897 INFO] Loaded tgt vocab has 8615 tokens.\n",
      "[2022-03-11 05:59:57,901 INFO] Building fields with vocab in counters...\n",
      "[2022-03-11 05:59:57,912 INFO]  * tgt vocab size: 8619.\n",
      "[2022-03-11 05:59:57,927 INFO]  * src vocab size: 9485.\n",
      "[2022-03-11 05:59:57,928 INFO]  * src vocab size = 9485\n",
      "[2022-03-11 05:59:57,928 INFO]  * tgt vocab size = 8619\n",
      "[2022-03-11 05:59:57,931 INFO] Building model...\n",
      "[2022-03-11 06:00:00,214 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9485, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rnn): LSTM(500, 500, num_layers=3, dropout=0.2)\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8619, 500, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.2, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(1000, 500)\n",
      "        (1): LSTMCell(500, 500)\n",
      "      )\n",
      "    )\n",
      "    (attn): GlobalAttention(\n",
      "      (linear_context): Linear(in_features=500, out_features=500, bias=False)\n",
      "      (linear_query): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (v): Linear(in_features=500, out_features=1, bias=False)\n",
      "      (linear_out): Linear(in_features=1000, out_features=500, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=8619, bias=True)\n",
      "    (1): Cast()\n",
      "    (2): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "[2022-03-11 06:00:00,215 INFO] encoder: 10754500\n",
      "[2022-03-11 06:00:00,215 INFO] decoder: 14637119\n",
      "[2022-03-11 06:00:00,215 INFO] * number of parameters: 25391619\n",
      "[2022-03-11 06:00:00,217 INFO] Starting training on GPU: [0]\n",
      "[2022-03-11 06:00:00,217 INFO] Start training loop and validate every 500 steps...\n",
      "[2022-03-11 06:00:00,217 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2022-03-11 06:00:00,218 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2022-03-11 06:00:15,339 INFO] Step 100/10000; acc:  19.26; ppl: 295.41; xent: 5.69; lr: 0.00100; 5223/5344 tok/s;     15 sec\n",
      "[2022-03-11 06:00:30,229 INFO] Step 200/10000; acc:  31.35; ppl: 80.01; xent: 4.38; lr: 0.00100; 5111/5323 tok/s;     30 sec\n",
      "[2022-03-11 06:00:45,409 INFO] Step 300/10000; acc:  36.78; ppl: 43.61; xent: 3.78; lr: 0.00100; 5250/5406 tok/s;     45 sec\n",
      "[2022-03-11 06:01:01,064 INFO] Step 400/10000; acc:  38.95; ppl: 36.23; xent: 3.59; lr: 0.00100; 5261/5463 tok/s;     61 sec\n",
      "[2022-03-11 06:01:08,953 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2022-03-11 06:01:16,779 INFO] Step 500/10000; acc:  39.76; ppl: 38.02; xent: 3.64; lr: 0.00100; 5270/5394 tok/s;     77 sec\n",
      "[2022-03-11 06:01:16,779 INFO] valid's transforms: TransformPipe()\n",
      "[2022-03-11 06:01:19,111 INFO] Validation perplexity: 29.5626\n",
      "[2022-03-11 06:01:19,111 INFO] Validation accuracy: 42.364\n",
      "[2022-03-11 06:01:19,112 INFO] Model is improving ppl: inf --> 29.5626.\n",
      "[2022-03-11 06:01:19,112 INFO] Model is improving acc: -inf --> 42.364.\n",
      "[2022-03-11 06:01:19,205 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_500.pt\n",
      "[2022-03-11 06:01:35,851 INFO] Step 600/10000; acc:  43.67; ppl: 30.20; xent: 3.41; lr: 0.00100; 4061/4195 tok/s;     96 sec\n",
      "[2022-03-11 06:01:50,861 INFO] Step 700/10000; acc:  46.48; ppl: 20.46; xent: 3.02; lr: 0.00100; 5170/5339 tok/s;    111 sec\n",
      "[2022-03-11 06:02:06,031 INFO] Step 800/10000; acc:  48.23; ppl: 17.92; xent: 2.89; lr: 0.00100; 5279/5490 tok/s;    126 sec\n",
      "[2022-03-11 06:02:21,479 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2022-03-11 06:02:22,061 INFO] Step 900/10000; acc:  47.20; ppl: 19.34; xent: 2.96; lr: 0.00100; 5215/5412 tok/s;    142 sec\n",
      "[2022-03-11 06:02:37,114 INFO] Step 1000/10000; acc:  50.42; ppl: 17.06; xent: 2.84; lr: 0.00100; 5275/5393 tok/s;    157 sec\n",
      "[2022-03-11 06:02:38,728 INFO] Validation perplexity: 17.6895\n",
      "[2022-03-11 06:02:38,728 INFO] Validation accuracy: 50.0493\n",
      "[2022-03-11 06:02:38,728 INFO] Model is improving ppl: 29.5626 --> 17.6895.\n",
      "[2022-03-11 06:02:38,728 INFO] Model is improving acc: 42.364 --> 50.0493.\n",
      "[2022-03-11 06:02:38,821 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_1000.pt\n",
      "[2022-03-11 06:02:55,515 INFO] Step 1100/10000; acc:  53.12; ppl: 13.34; xent: 2.59; lr: 0.00100; 4160/4324 tok/s;    175 sec\n",
      "[2022-03-11 06:03:10,722 INFO] Step 1200/10000; acc:  54.13; ppl: 11.25; xent: 2.42; lr: 0.00100; 5236/5391 tok/s;    191 sec\n",
      "[2022-03-11 06:03:26,176 INFO] Step 1300/10000; acc:  54.80; ppl: 10.74; xent: 2.37; lr: 0.00100; 5279/5499 tok/s;    206 sec\n",
      "[2022-03-11 06:03:33,487 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2022-03-11 06:03:41,973 INFO] Step 1400/10000; acc:  53.38; ppl: 12.13; xent: 2.50; lr: 0.00100; 5233/5362 tok/s;    222 sec\n",
      "[2022-03-11 06:03:57,221 INFO] Step 1500/10000; acc:  57.75; ppl:  9.29; xent: 2.23; lr: 0.00100; 5203/5352 tok/s;    237 sec\n",
      "[2022-03-11 06:03:58,834 INFO] Validation perplexity: 13.0005\n",
      "[2022-03-11 06:03:58,835 INFO] Validation accuracy: 54.6393\n",
      "[2022-03-11 06:03:58,835 INFO] Model is improving ppl: 17.6895 --> 13.0005.\n",
      "[2022-03-11 06:03:58,835 INFO] Model is improving acc: 50.0493 --> 54.6393.\n",
      "[2022-03-11 06:03:58,930 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_1500.pt\n",
      "[2022-03-11 06:04:18,547 INFO] Step 1600/10000; acc:  59.75; ppl:  7.48; xent: 2.01; lr: 0.00100; 3522/3661 tok/s;    258 sec\n",
      "[2022-03-11 06:04:33,872 INFO] Step 1700/10000; acc:  59.80; ppl:  7.46; xent: 2.01; lr: 0.00100; 5266/5457 tok/s;    274 sec\n",
      "[2022-03-11 06:04:48,688 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2022-03-11 06:04:49,864 INFO] Step 1800/10000; acc:  58.01; ppl:  8.23; xent: 2.11; lr: 0.00100; 5217/5408 tok/s;    290 sec\n",
      "[2022-03-11 06:05:05,000 INFO] Step 1900/10000; acc:  61.07; ppl:  6.89; xent: 1.93; lr: 0.00100; 5301/5409 tok/s;    305 sec\n",
      "[2022-03-11 06:05:19,815 INFO] Step 2000/10000; acc:  64.06; ppl:  5.62; xent: 1.73; lr: 0.00100; 5200/5417 tok/s;    320 sec\n",
      "[2022-03-11 06:05:21,428 INFO] Validation perplexity: 8.52481\n",
      "[2022-03-11 06:05:21,428 INFO] Validation accuracy: 60.3065\n",
      "[2022-03-11 06:05:21,428 INFO] Model is improving ppl: 13.0005 --> 8.52481.\n",
      "[2022-03-11 06:05:21,428 INFO] Model is improving acc: 54.6393 --> 60.3065.\n",
      "[2022-03-11 06:05:21,520 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_2000.pt\n",
      "[2022-03-11 06:05:40,741 INFO] Step 2100/10000; acc:  64.49; ppl:  5.36; xent: 1.68; lr: 0.00100; 3760/3874 tok/s;    341 sec\n",
      "[2022-03-11 06:05:56,145 INFO] Step 2200/10000; acc:  64.58; ppl:  5.34; xent: 1.67; lr: 0.00100; 5273/5480 tok/s;    356 sec\n",
      "[2022-03-11 06:06:02,890 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2022-03-11 06:06:12,263 INFO] Step 2300/10000; acc:  62.48; ppl:  5.94; xent: 1.78; lr: 0.00100; 5255/5373 tok/s;    372 sec\n",
      "[2022-03-11 06:06:27,137 INFO] Step 2400/10000; acc:  68.78; ppl:  4.06; xent: 1.40; lr: 0.00100; 5195/5379 tok/s;    387 sec\n",
      "[2022-03-11 06:06:41,806 INFO] Step 2500/10000; acc:  69.12; ppl:  3.96; xent: 1.38; lr: 0.00100; 5154/5347 tok/s;    402 sec\n",
      "[2022-03-11 06:06:43,426 INFO] Validation perplexity: 7.41437\n",
      "[2022-03-11 06:06:43,426 INFO] Validation accuracy: 63.106\n",
      "[2022-03-11 06:06:43,426 INFO] Model is improving ppl: 8.52481 --> 7.41437.\n",
      "[2022-03-11 06:06:43,426 INFO] Model is improving acc: 60.3065 --> 63.106.\n",
      "[2022-03-11 06:06:43,515 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_2500.pt\n",
      "[2022-03-11 06:07:03,308 INFO] Step 2600/10000; acc:  68.72; ppl:  4.09; xent: 1.41; lr: 0.00100; 3749/3879 tok/s;    423 sec\n",
      "[2022-03-11 06:07:17,357 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2022-03-11 06:07:19,207 INFO] Step 2700/10000; acc:  66.88; ppl:  4.47; xent: 1.50; lr: 0.00100; 5263/5458 tok/s;    439 sec\n",
      "[2022-03-11 06:07:34,526 INFO] Step 2800/10000; acc:  70.70; ppl:  3.57; xent: 1.27; lr: 0.00100; 5285/5398 tok/s;    454 sec\n",
      "[2022-03-11 06:07:49,239 INFO] Step 2900/10000; acc:  73.88; ppl:  3.00; xent: 1.10; lr: 0.00100; 5201/5410 tok/s;    469 sec\n",
      "[2022-03-11 06:08:04,224 INFO] Step 3000/10000; acc:  72.83; ppl:  3.15; xent: 1.15; lr: 0.00100; 5213/5375 tok/s;    484 sec\n",
      "[2022-03-11 06:08:05,837 INFO] Validation perplexity: 6.89515\n",
      "[2022-03-11 06:08:05,838 INFO] Validation accuracy: 64.5702\n",
      "[2022-03-11 06:08:05,838 INFO] Model is improving ppl: 7.41437 --> 6.89515.\n",
      "[2022-03-11 06:08:05,838 INFO] Model is improving acc: 63.106 --> 64.5702.\n",
      "[2022-03-11 06:08:05,927 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_3000.pt\n",
      "[2022-03-11 06:08:27,020 INFO] Step 3100/10000; acc:  71.81; ppl:  3.35; xent: 1.21; lr: 0.00100; 3617/3744 tok/s;    507 sec\n",
      "[2022-03-11 06:08:38,035 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 8\n",
      "[2022-03-11 06:08:42,877 INFO] Step 3200/10000; acc:  71.18; ppl:  3.44; xent: 1.24; lr: 0.00100; 5220/5380 tok/s;    523 sec\n",
      "[2022-03-11 06:08:57,776 INFO] Step 3300/10000; acc:  77.80; ppl:  2.46; xent: 0.90; lr: 0.00100; 5234/5394 tok/s;    538 sec\n",
      "[2022-03-11 06:09:12,495 INFO] Step 3400/10000; acc:  76.49; ppl:  2.58; xent: 0.95; lr: 0.00100; 5160/5366 tok/s;    552 sec\n",
      "[2022-03-11 06:09:27,837 INFO] Step 3500/10000; acc:  75.97; ppl:  2.69; xent: 0.99; lr: 0.00100; 5275/5436 tok/s;    568 sec\n",
      "[2022-03-11 06:09:29,453 INFO] Validation perplexity: 6.78194\n",
      "[2022-03-11 06:09:29,453 INFO] Validation accuracy: 66.1634\n",
      "[2022-03-11 06:09:29,453 INFO] Model is improving ppl: 6.89515 --> 6.78194.\n",
      "[2022-03-11 06:09:29,453 INFO] Model is improving acc: 64.5702 --> 66.1634.\n",
      "[2022-03-11 06:09:29,544 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_3500.pt\n",
      "[2022-03-11 06:09:49,711 INFO] Step 3600/10000; acc:  73.75; ppl:  2.96; xent: 1.09; lr: 0.00100; 3827/3974 tok/s;    589 sec\n",
      "[2022-03-11 06:09:52,290 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 9\n",
      "[2022-03-11 06:10:05,020 INFO] Step 3700/10000; acc:  78.21; ppl:  2.39; xent: 0.87; lr: 0.00100; 5269/5387 tok/s;    605 sec\n",
      "[2022-03-11 06:10:19,763 INFO] Step 3800/10000; acc:  80.89; ppl:  2.07; xent: 0.73; lr: 0.00100; 5187/5394 tok/s;    620 sec\n",
      "[2022-03-11 06:10:35,041 INFO] Step 3900/10000; acc:  78.65; ppl:  2.31; xent: 0.84; lr: 0.00100; 5192/5329 tok/s;    635 sec\n",
      "[2022-03-11 06:10:50,274 INFO] Step 4000/10000; acc:  78.82; ppl:  2.30; xent: 0.83; lr: 0.00100; 5247/5472 tok/s;    650 sec\n",
      "[2022-03-11 06:10:51,897 INFO] Validation perplexity: 6.93374\n",
      "[2022-03-11 06:10:51,897 INFO] Validation accuracy: 65.5868\n",
      "[2022-03-11 06:10:51,897 INFO] Decreasing patience: 1/2\n",
      "[2022-03-11 06:10:51,984 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_4000.pt\n",
      "[2022-03-11 06:11:04,042 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 10\n",
      "[2022-03-11 06:11:09,747 INFO] Step 4100/10000; acc:  76.86; ppl:  2.49; xent: 0.91; lr: 0.00100; 4292/4429 tok/s;    670 sec\n",
      "[2022-03-11 06:11:24,808 INFO] Step 4200/10000; acc:  83.29; ppl:  1.87; xent: 0.62; lr: 0.00100; 5213/5356 tok/s;    685 sec\n",
      "[2022-03-11 06:11:39,519 INFO] Step 4300/10000; acc:  82.10; ppl:  1.95; xent: 0.67; lr: 0.00100; 5183/5381 tok/s;    699 sec\n",
      "[2022-03-11 06:11:54,907 INFO] Step 4400/10000; acc:  80.87; ppl:  2.07; xent: 0.73; lr: 0.00100; 5261/5422 tok/s;    715 sec\n",
      "[2022-03-11 06:12:10,708 INFO] Step 4500/10000; acc:  79.73; ppl:  2.18; xent: 0.78; lr: 0.00100; 5238/5453 tok/s;    730 sec\n",
      "[2022-03-11 06:12:12,326 INFO] Validation perplexity: 7.29272\n",
      "[2022-03-11 06:12:12,326 INFO] Validation accuracy: 66.3379\n",
      "[2022-03-11 06:12:12,326 INFO] Stalled patience: 1/2\n",
      "[2022-03-11 06:12:12,413 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_4500.pt\n",
      "[2022-03-11 06:12:15,812 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 11\n",
      "[2022-03-11 06:12:29,467 INFO] Step 4600/10000; acc:  82.53; ppl:  1.92; xent: 0.65; lr: 0.00100; 4314/4394 tok/s;    749 sec\n",
      "[2022-03-11 06:12:44,574 INFO] Step 4700/10000; acc:  85.15; ppl:  1.71; xent: 0.54; lr: 0.00100; 5184/5380 tok/s;    764 sec\n",
      "[2022-03-11 06:12:59,415 INFO] Step 4800/10000; acc:  83.80; ppl:  1.82; xent: 0.60; lr: 0.00100; 5174/5348 tok/s;    779 sec\n",
      "[2022-03-11 06:13:14,830 INFO] Step 4900/10000; acc:  83.17; ppl:  1.85; xent: 0.62; lr: 0.00100; 5231/5445 tok/s;    795 sec\n",
      "[2022-03-11 06:13:24,644 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 12\n",
      "[2022-03-11 06:13:30,827 INFO] Step 5000/10000; acc:  81.10; ppl:  2.03; xent: 0.71; lr: 0.00100; 5232/5406 tok/s;    811 sec\n",
      "[2022-03-11 06:13:32,446 INFO] Validation perplexity: 8.08037\n",
      "[2022-03-11 06:13:32,446 INFO] Validation accuracy: 65.9282\n",
      "[2022-03-11 06:13:32,446 INFO] Decreasing patience: 0/2\n",
      "[2022-03-11 06:13:32,446 INFO] Training finished after not improving. Early Stop!\n",
      "[2022-03-11 06:13:32,446 INFO] Best model found at step 3500\n",
      "[2022-03-11 06:13:32,545 INFO] Saving checkpoint drive/MyDrive/Lab3/data/run/model_step_5000.pt\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config multi30k.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6WGJkJym-y9"
   },
   "source": [
    "\n",
    "# Decoding\n",
    "\n",
    "Once our model is saved. We can use it to actually generate predictions on our output files. Our models will be saved under the ```save_model``` setting of our config file.\n",
    "\n",
    "We create predictions for the validation set using your saved models and select the one that has the highest BLEU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3n0ezhfm9q9"
   },
   "outputs": [],
   "source": [
    "## Code to create predictions and calculate BLEU for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmFrKaN5bPlj",
    "outputId": "e8199099-056e-4e31-a065-a61453384de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-11 06:37:43,982 INFO] Translating shard 0.\n",
      "[2022-03-11 06:38:06,127 INFO] PRED AVG SCORE: -0.4101, PRED PPL: 1.5070\n",
      "[2022-03-11 06:38:09,733 INFO] Translating shard 0.\n",
      "[2022-03-11 06:38:32,359 INFO] PRED AVG SCORE: -0.3432, PRED PPL: 1.4094\n",
      "[2022-03-11 06:38:35,987 INFO] Translating shard 0.\n",
      "[2022-03-11 06:38:57,039 INFO] PRED AVG SCORE: -0.3328, PRED PPL: 1.3948\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4000.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_4000.txt -gpu 0 -beam_size 5 -seed 531 -block_ngram 2\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_4500.txt -gpu 0 -beam_size 5 -seed 531 -block_ngram 2\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_5000.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_5000.txt -gpu 0 -beam_size 5 -seed 531 -block_ngram 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's calculate the BLEU scores of the outputs! We would eventually want to select the model with Highest BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF455v2ocJv8",
    "outputId": "dea78711-f1ed-400e-ebeb-abbcbdf8262e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 35.79, 63.1/43.1/29.8/20.9 (BP=0.992, ratio=0.993, hyp_len=12076, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 36.45, 63.6/43.1/30.0/21.4 (BP=1.000, ratio=1.010, hyp_len=12287, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 35.87, 65.1/44.2/30.6/21.5 (BP=0.966, ratio=0.967, hyp_len=11766, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_4000.txt\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_4500.txt\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_5000.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcF9qBqknZg0"
   },
   "source": [
    "# Comparing Beam Width\n",
    "\n",
    "For our BEST model we compare the peformance (Both BLEU and clocktime to run)  with the following Beam Sizes: 5 (done above), 10, 15, and 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkYdBODGoJIM",
    "outputId": "84f24ea7-64ee-4764-f395-5718ebb37366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-11 06:49:00,667 INFO] Translating shard 0.\n",
      "[2022-03-11 06:49:22,714 INFO] PRED AVG SCORE: -0.3432, PRED PPL: 1.4094\n",
      "[2022-03-11 06:49:26,365 INFO] Translating shard 0.\n",
      "[2022-03-11 06:50:07,621 INFO] PRED AVG SCORE: -0.3388, PRED PPL: 1.4033\n",
      "[2022-03-11 06:50:11,329 INFO] Translating shard 0.\n",
      "[2022-03-11 06:51:09,823 INFO] PRED AVG SCORE: -0.3372, PRED PPL: 1.4010\n",
      "[2022-03-11 06:51:13,559 INFO] Translating shard 0.\n",
      "[2022-03-11 06:52:26,839 INFO] PRED AVG SCORE: -0.3371, PRED PPL: 1.4009\n"
     ]
    }
   ],
   "source": [
    "## TODO Beam comparison\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_4500_5.txt -gpu 0 -beam_size 5 -seed 531 -block_ngram 2\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_4500_10.txt -gpu 0 -beam_size 10 -seed 531 -block_ngram 2\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_4500_15.txt -gpu 0 -beam_size 15 -seed 531 -block_ngram 2\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/val_fre.txt -output drive/MyDrive/Lab3/data/val_4500_20.txt -gpu 0 -beam_size 20 -seed 531 -block_ngram 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S7zQMlelvPSr",
    "outputId": "467c64b2-4fc6-4799-c4fe-01fb2b6e4ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 36.45, 63.6/43.1/30.0/21.4 (BP=1.000, ratio=1.010, hyp_len=12287, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 36.89, 64.1/43.7/30.4/21.7 (BP=1.000, ratio=1.001, hyp_len=12180, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 36.98, 64.3/43.9/30.7/21.9 (BP=0.997, ratio=0.997, hyp_len=12125, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 37.00, 64.5/44.0/30.8/22.0 (BP=0.994, ratio=0.994, hyp_len=12096, ref_len=12167)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_4500_5.txt\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_4500_10.txt\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_4500_15.txt\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/val_eng.txt < drive/MyDrive/Lab3/data/val_4500_20.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIcV8H5St2PD"
   },
   "source": [
    "Evaluation on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GU_UAbkFw6Vl",
    "outputId": "4477f009-bce7-4f47-dc14-fa119a177f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-11 20:56:48,989 INFO] Translating shard 0.\n",
      "[2022-03-11 20:57:55,358 INFO] PRED AVG SCORE: -0.3363, PRED PPL: 1.3998\n",
      "BLEU = 38.55, 65.3/45.3/32.0/23.6 (BP=0.997, ratio=0.997, hyp_len=11841, ref_len=11877)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/test_fre.txt -output drive/MyDrive/Lab3/data/test_4500.txt -gpu 0 -beam_size 20 -seed 531 -block_ngram 2\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/test_eng.txt < drive/MyDrive/Lab3/data/test_4500.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmddbsXxqvjD"
   },
   "source": [
    "BLEU scores for Long and short test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mR_7Pbqt6tX",
    "outputId": "4ce6226f-2fb5-470b-e7bc-8a87cd8e2284"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-11 20:39:23,882 INFO] Translating shard 0.\n",
      "[2022-03-11 20:39:32,834 INFO] PRED AVG SCORE: -0.5017, PRED PPL: 1.6515\n",
      "[2022-03-11 20:39:36,459 INFO] Translating shard 0.\n",
      "[2022-03-11 20:39:39,335 INFO] PRED AVG SCORE: -0.2544, PRED PPL: 1.2897\n"
     ]
    }
   ],
   "source": [
    "#long\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/long_test_fre.txt -output drive/MyDrive/Lab3/data/long_test_4500.txt -gpu 0 -beam_size 20 -seed 531 -block_ngram 2\n",
    "#short\n",
    "!onmt_translate -model drive/MyDrive/Lab3/data/run/model_step_4500.pt -src drive/MyDrive/Lab3/data/short_test_fre.txt -output drive/MyDrive/Lab3/data/short_test_4500.txt -gpu 0 -beam_size 20 -seed 531 -block_ngram 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "obcjEH43q6Jh",
    "outputId": "713a86ec-8d61-4e88-ea14-7c67e72a14fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 28.93, 60.5/37.8/24.4/16.3 (BP=0.937, ratio=0.938, hyp_len=1342, ref_len=1430)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n",
      "BLEU = 37.77, 62.4/45.0/31.7/22.9 (BP=1.000, ratio=1.082, hyp_len=609, ref_len=563)\n",
      "It is not advisable to publish scores from multi-bleu.perl.  The scores depend on your tokenizer, which is unlikely to be reproducible from your paper or consistent across research groups.  Instead you should detokenize then use mteval-v14.pl, which has a standard tokenization.  Scores from multi-bleu.perl can still be used for internal purposes when you have a consistent tokenizer.\n"
     ]
    }
   ],
   "source": [
    "#Long\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/long_test_eng.txt < drive/MyDrive/Lab3/data/long_test_4500.txt\n",
    "#Short\n",
    "!perl  drive/MyDrive/Lab3/multi-bleu.perl drive/MyDrive/Lab3/data/short_test_eng.txt < drive/MyDrive/Lab3/data/short_test_4500.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KLv4D8VIV_s"
   },
   "source": [
    "Working on transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JFXIUvZjIVYu",
    "outputId": "63a6e743-8fe4-4f2f-cc9f-3010d2124cec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2022-03-11 22:49:03,335 INFO] Counter vocab from 10000 samples.\n",
      "[2022-03-11 22:49:03,335 INFO] Build vocab on 10000 transformed examples/corpus.\n",
      "[2022-03-11 22:49:03,344 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2022-03-11 22:49:03,549 INFO] Counters src:9483\n",
      "[2022-03-11 22:49:03,549 INFO] Counters tgt:8615\n"
     ]
    }
   ],
   "source": [
    "!onmt_build_vocab -config multi30k-Transform.yml -n_sample 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Txh5nE_1JyS-",
    "outputId": "02a779b0-6335-496a-bbf1-582fd5508e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-11 22:49:07,896 INFO] Missing transforms field for corpus_1 data, set to default: [].\n",
      "[2022-03-11 22:49:07,897 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
      "[2022-03-11 22:49:07,897 INFO] Missing transforms field for valid data, set to default: [].\n",
      "[2022-03-11 22:49:07,897 INFO] Parsed 2 corpora from -data.\n",
      "[2022-03-11 22:49:07,898 INFO] Get special vocabs from Transforms: {'src': set(), 'tgt': set()}.\n",
      "[2022-03-11 22:49:07,898 INFO] Loading vocab from text file...\n",
      "[2022-03-11 22:49:07,898 INFO] Loading src vocabulary from drive/MyDrive/Lab3/data/run/example_transform.vocab.src\n",
      "[2022-03-11 22:49:07,925 INFO] Loaded src vocab has 9483 tokens.\n",
      "[2022-03-11 22:49:07,930 INFO] Loading tgt vocabulary from drive/MyDrive/Lab3/data/run/example_transform.vocab.tgt\n",
      "[2022-03-11 22:49:07,951 INFO] Loaded tgt vocab has 8615 tokens.\n",
      "[2022-03-11 22:49:07,955 INFO] Building fields with vocab in counters...\n",
      "[2022-03-11 22:49:07,965 INFO]  * tgt vocab size: 8619.\n",
      "[2022-03-11 22:49:07,978 INFO]  * src vocab size: 9485.\n",
      "[2022-03-11 22:49:07,979 INFO]  * src vocab size = 9485\n",
      "[2022-03-11 22:49:07,979 INFO]  * tgt vocab size = 8619\n",
      "[2022-03-11 22:49:07,982 INFO] Building model...\n",
      "[2022-03-11 22:49:10,841 INFO] NMTModel(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(9485, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (transformer): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): TransformerEncoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(8619, 512, padding_idx=1)\n",
      "        )\n",
      "        (pe): PositionalEncoding(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "    (transformer_layers): ModuleList(\n",
      "      (0): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayer(\n",
      "        (self_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "        (context_attn): MultiHeadedAttention(\n",
      "          (linear_keys): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_values): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (final_linear): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=8619, bias=True)\n",
      "    (1): Cast()\n",
      "    (2): LogSoftmax(dim=-1)\n",
      "  )\n",
      ")\n",
      "[2022-03-11 22:49:10,936 INFO] encoder: 23771648\n",
      "[2022-03-11 22:49:10,936 INFO] decoder: 34059691\n",
      "[2022-03-11 22:49:10,936 INFO] * number of parameters: 57831339\n",
      "[2022-03-11 22:49:10,940 INFO] Starting training on GPU: [0]\n",
      "[2022-03-11 22:49:10,940 INFO] Start training loop and validate every 500 steps...\n",
      "[2022-03-11 22:49:10,940 INFO] corpus_1's transforms: TransformPipe()\n",
      "[2022-03-11 22:49:10,940 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 1\n",
      "[2022-03-11 22:51:22,400 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 2\n",
      "[2022-03-11 22:53:42,613 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 3\n",
      "[2022-03-11 22:55:55,983 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 4\n",
      "[2022-03-11 22:58:18,493 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 5\n",
      "[2022-03-11 23:00:38,066 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 6\n",
      "[2022-03-11 23:02:51,058 INFO] Weighted corpora loaded so far:\n",
      "\t\t\t* corpus_1: 7\n",
      "[2022-03-11 23:02:59,662 INFO] Step 100/10000; acc:  22.97; ppl: 111.99; xent: 4.72; lr: 0.00112; 2604/2690 tok/s;    829 sec\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/bin/onmt_train\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('OpenNMT-py', 'console_scripts', 'onmt_train')())\n",
      "  File \"/content/OpenNMT-py/onmt/bin/train.py\", line 172, in main\n",
      "    train(opt)\n",
      "  File \"/content/OpenNMT-py/onmt/bin/train.py\", line 157, in train\n",
      "    train_process(opt, device_id=0)\n",
      "  File \"/content/OpenNMT-py/onmt/train_single.py\", line 114, in main\n",
      "    valid_steps=opt.valid_steps)\n",
      "  File \"/content/OpenNMT-py/onmt/trainer.py\", line 244, in train\n",
      "    report_stats)\n",
      "  File \"/content/OpenNMT-py/onmt/trainer.py\", line 379, in _gradient_accumulation\n",
      "    trunc_size=trunc_size)\n",
      "  File \"/content/OpenNMT-py/onmt/utils/loss.py\", line 195, in __call__\n",
      "    for shard in shards(shard_state, shard_size):\n",
      "  File \"/content/OpenNMT-py/onmt/utils/loss.py\", line 457, in shards\n",
      "    torch.autograd.backward(inputs, grads)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 127, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -config multi30k-Transform.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four models analysed: (1) basic seq2seq model; (2) seq2seq with additive attention ; (3) seq2seq variant with Bidirectional LSTM encoder; and finally (4) Open-NMT seq2seq with MLP attention. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative BLEU-4 score on test set:\n",
    "- For model (1), **my best model obtains 24.95 cumulative BLEU-4 score with 8 epoch(s).** \n",
    "- For model (2), **my best model obtains 41.8 cumulative BLEU-4 score with 4 epoch(s).** \n",
    "- For model (3), **my best model obtains 24.55 cumulative BLEU-4 score with 6 epoch(s).** \n",
    "- For model (4), **my best model obtains 38.55 cumulative BLEU-4 score with 4500 epoch(s).** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative BLEU-4 score on long sentences of test set:\n",
    "- For model (1), **my best model obtains 15.19 cumulative BLEU-4.** \n",
    "- For model (2), **my best model obtains 30.4 cumulative BLEU-4.**\n",
    "- For model (3), **my best model obtains 15.91 cumulative BLEU-4.**\n",
    "- For model (4), **my best model obtains 28.93 cumulative BLEU-4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cumulative BLEU-4 score on short sentences of test set:\n",
    "- For model (1), **my best model obtains 32.15 cumulative BLEU-4.** \n",
    "- For model (2), **my best model obtains 39.4 cumulative BLEU-4.**\n",
    "- For model (3), **my best model obtains 31.96 cumulative BLEU-4.**\n",
    "- For model (4), **my best model obtains 37.77 cumulative BLEU-4.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison:\n",
    "\n",
    "1) When compared to the other models, the attention-based model performs the best. The cumulative BLEU-4 score from the attention-based model is 41.8. \n",
    "2) With a total BLEU-4 score of 38.55, the openNMT rnn-based model comes in second. \n",
    "3) The regular seq2seq model with BLEU score-24.95 outperforms the bidirectional lstm encoder seq2seq model with BLEU score-24.55. \n",
    "4) As the length of the phrases is increased or when long sentences are fed into the corresponding models, the BLEU scores decline, and therefore the performance decreases."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "OpenNMT_T3-2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
